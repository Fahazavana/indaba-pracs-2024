{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# **IA Responsable (Responsible AI)**\n",
        "**Partie 1 : Analyse de l'outil COMPAS par ProPublica**\n",
        "\n",
        "**Partie 2 : Détection et atténuation des biais à l'aide de Fairlearn**\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1W3nZF2AUsSbIKo_ekazO_rYDcPQSRzi8\" width=\"50%\" />\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1tWWxMkonHYbZi_J7wDTr2Zl2CCHKyZPD\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "© Deep Learning Indaba 2024. Apache License 2.0.\n",
        "\n",
        "**Auteurs :** Umang Bhatt et Kendall Brogle\n",
        "\n",
        "**Introduction :**\n",
        "\n",
        "Ce bloc-notes propose une exploration pratique de l'IA responsable en deux parties : analyser l'analyse de ProPublica de l'outil d'évaluation des risques COMPAS et examiner les biais à l'aide de la boîte à outils Fairlearn. La première partie se concentre sur l'enquête de ProPublica sur COMPAS, en particulier sur la manière dont ses scores de récidive varient selon la race et le sexe. Cela implique l'importation de données, le prétraitement, l'analyse exploratoire et la modélisation par régression logistique pour reproduire et interpréter les résultats de ProPublica. La deuxième partie passe à la détection et à l'atténuation des biais à l'aide de Fairlearn, une bibliothèque conçue pour évaluer et améliorer l'équité des modèles de Machine Learning. En abordant les aspects à la fois théoriques et pratiques de l'IA responsable, ce bloc-notes vise à améliorer la compréhension des biais dans les systèmes d'IA et des outils disponibles pour y remédier.\n",
        "\n",
        "**Sujets :**\n",
        "\n",
        "Contenu : IA responsable, Détection et atténuation des biais, Régression logistique, Équité dans les modèles d'IA\n",
        "\n",
        "Niveau : Intermédiaire, Avancé\n",
        "\n",
        "\n",
        "**Objectifs/Objectifs d'apprentissage :**\n",
        "\n",
        "1) Comprendre et analyser les biais dans l'outil d'évaluation des risques COMPAS.\n",
        "\n",
        "2) Appliquer la régression logistique pour explorer les biais raciaux dans les scores de risque.\n",
        "\n",
        "3) Utiliser le package Fairlearn pour détecter et atténuer les biais dans les modèles.\n",
        "\n",
        "4) Évaluer l'équité à l'aide de mesures telles que la différence et le ratio de parité démographique.\n",
        "\n",
        "\n",
        "**Prérequis :**\n",
        "\n",
        "Compréhension de base des concepts de Machine Learning.\n",
        "\n",
        "Familiarité avec Python et des bibliothèques telles que Pandas, Scikit-learn et Matplotlib.\n",
        "\n",
        "Compréhension de la régression logistique et des mesures de classification.\n",
        "\n",
        "Familiarité avec les concepts de biais et d'équité en IA.\n",
        "\n",
        "**Plan :**\n",
        "\n",
        ">[Installation et importations](#scrollTo=6EqhIg1odqg0)\n",
        "\n",
        ">[Partie 1 : Analyse de l'outil COMPAS par ProPublica](#scrollTo=G2sewZEq36T0)\n",
        "\n",
        ">[Partie 2 : Détection et atténuation des biais à l'aide de Fairlearn](#scrollTo=253jTpcO60Mf)\n",
        "\n",
        ">[Conclusion](#scrollTo=fV3YG7QOZD-B)\n",
        "\n",
        "**Avant de commencer :**\n",
        "\n",
        "Assurez-vous que tous les packages Python requis sont installés.\n",
        "\n",
        "Familiarisez-vous avec l'ensemble de données et les descriptions des variables.\n",
        "\n",
        "Revoyez les concepts clés de la régression logistique et des biais en IA.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EqhIg1odqg0"
      },
      "source": [
        "## Installation et importations\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xkOSgm_WjCVO"
      },
      "outputs": [],
      "source": [
        "## Installation et importations requises. Capture cache la sortie de la cellule.\n",
        "# @title Installer et importer les paquets requis. (Exécuter la cellule)\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Fonction pour vérifier la présence d'un GPU/TPU et configurer l'environnement\n",
        "def check_accelerator():\n",
        "    try:\n",
        "        subprocess.check_output('nvidia-smi')\n",
        "        print(\"Un GPU est connecté.\")\n",
        "    except Exception:\n",
        "        # TPU ou CPU\n",
        "        if \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "            print(\"Un TPU est connecté.\")\n",
        "            import jax.tools.colab_tpu\n",
        "            jax.tools.colab_tpu.setup_tpu()\n",
        "        else:\n",
        "            print(\"Seul l'accélérateur CPU est connecté.\")\n",
        "            # x8 périphériques CPU - nombre de périphériques hôtes (émulés)\n",
        "            os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
        "\n",
        "check_accelerator()\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.metrics as skm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Importer les données\n",
        "url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
        "\n",
        "# Pour la partie 2\n",
        "# @markdown\n",
        "!pip install fairlearn folktables\n",
        "!git clone https://github.com/lurosenb/superquail\n",
        "\n",
        "from folktables import ACSDataSource, ACSEmployment, ACSIncome, ACSPublicCoverage, ACSTravelTime\n",
        "from superquail.data.acs_helper import ACSData\n",
        "from fairlearn.datasets import fetch_adult\n",
        "from fairlearn.preprocessing import CorrelationRemover\n",
        "from fairlearn.reductions import ExponentiatedGradient, GridSearch, DemographicParity, ErrorRate\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "from fairlearn.metrics import MetricFrame, demographic_parity_difference, demographic_parity_ratio, selection_rate, false_negative_rate, false_positive_rate\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2sewZEq36T0"
      },
      "source": [
        "# **Partie 1 : Analyse de l'outil COMPAS par ProPublica**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "355LmyCRd_sZ"
      },
      "source": [
        "En 2016, [ProPublica a publié une analyse](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) de l'outil d'évaluation des risques de récidive Correctional Offender Management Profiling for Alternative Sanctions (COMPAS). COMPAS est un outil propriétaire qui génère une soi-disant évaluation des risques pour les accusés dans un procès pénal. L'analyse de ProPublica s'est concentrée sur le « score de récidive », qui est censé fournir la probabilité de récidive (c'est-à-dire de commettre un délit ou un crime) dans les deux ans suivant l'évaluation.\n",
        "\n",
        "Dans ce laboratoire, nous allons passer en revue certaines parties de l'analyse de COMPAS par ProPublica, en nous concentrant sur la façon dont l'échelle de risque de récidive varie selon la race et le sexe.\n",
        "\n",
        "Cette section comporte quatre étapes au cours desquelles nous allons :\n",
        "1. Vérifier les données, mettre en œuvre quelques étapes de prétraitement et inspecter les données\n",
        "2. Exécuter une courte analyse exploratoire du score de récidive COMPAS, notre principale variable d'intérêt\n",
        "3. Reproduire le modèle de régression logistique de l'analyse de ProPublica et interpréter les estimations\n",
        "4. Calculer la précision prédictive des étiquettes de score de risque\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJDFA9XSwdMi"
      },
      "source": [
        "# Vérification des données\n",
        "\n",
        "Vérifiez les premières lignes de données du référentiel d'analyse compas de ProPublica sur GitHub :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5B1icC-sbBg"
      },
      "outputs": [],
      "source": [
        "df_compas = pd.read_csv(url)\n",
        "print(\"Forme : \", df_compas.shape) # Forme = Shape\n",
        "df_compas.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI0slRqXFyXZ"
      },
      "source": [
        "## Remarques sur les données\n",
        "\n",
        "Reportez-vous à la description de la [méthodologie de collecte des données](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm). Les points importants sont soulignés ci-dessous ; consultez la description complète de ProPublica pour plus de détails.\n",
        "\n",
        "> **Objectif :** Nous avons examiné plus de 10 000 accusés au criminel dans le comté de Broward, en Floride, et nous avons comparé leurs taux de récidive prédits au taux réellement observé sur une période de deux ans.\n",
        ">\n",
        "> **Données d'entrée de l'outil COMPAS (personnes concernées) :** Lorsque la plupart des accusés sont incarcérés, ils répondent à un questionnaire COMPAS. Leurs réponses sont saisies dans le logiciel COMPAS pour générer plusieurs scores, notamment des prédictions du risque de récidive et du risque de récidive violente.\n",
        ">\n",
        "> **Comment ProPublica a obtenu les données d'entrée de COMPAS :** Dans le cadre d'une demande d'accès aux documents publics, ProPublica a obtenu deux années de scores COMPAS auprès du bureau du shérif du comté de Broward en Floride. Nous avons reçu des données pour l'ensemble des 18 610 personnes qui ont obtenu un score en 2013 et 2014.\n",
        ">\n",
        "> **Sortie de l'outil COMPAS :** Chaque accusé en attente de procès a reçu au moins trois scores COMPAS : « Risque de récidive », « Risque de violence » et « Risque de non-comparution ». [...] Les scores COMPAS pour chaque accusé variaient de 1 à 10, dix étant le risque le plus élevé. Les scores de 1 à 4 ont été étiquetés par COMPAS comme « faibles » ; de 5 à 7 ont été étiquetés « moyens » ; et de 8 à 10 ont été étiquetés « élevés ».\n",
        ">\n",
        "> **Intégration des données (regroupement des enregistrements) :** À partir de la base de données des scores COMPAS, nous avons établi un profil des antécédents criminels de chaque personne, avant et après l'obtention du score. Nous avons recueilli des dossiers criminels publics sur le site Web du greffe du comté de Broward jusqu'au 1er avril 2016. En moyenne, les accusés de notre ensemble de données n'ont pas été incarcérés pendant 622,87 jours (écart type : 329,19). Nous avons apparié les dossiers criminels aux dossiers COMPAS en utilisant le prénom, le nom de famille et la date de naissance de la personne. Il s'agit de la même technique que celle utilisée dans l'étude de validation COMPAS du comté de Broward menée par des chercheurs de l'université d'État de Floride en 2010. Nous avons téléchargé environ 80 000 dossiers criminels à partir du site Web du greffe du comté de Broward.\n",
        ">\n",
        "> **Qu'est-ce que la recidive ?** Northpointe a défini la recidive comme « une arrestation avec prise d'empreintes digitales impliquant une accusation et un dépôt pour tout code de déclaration uniforme de la criminalité (DUC) ». Nous avons interprété cela comme signifiant une infraction criminelle ayant donné lieu à une mise en détention et ayant eu lieu après le crime pour lequel la personne a obtenu un score COMPAS. [...] Pour la plupart de nos analyses, nous avons défini la récidive comme une nouvelle arrestation dans un délai de deux ans.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0xgPnT11OtO"
      },
      "source": [
        "# Inspecter les données\n",
        "\n",
        "Par souci de commodité, voici un tableau des définitions des variables :\n",
        "\n",
        "| Variable    | Description |\n",
        "| ----------- | ----------- |\n",
        "| age       |  Âge de l'accusé   |\n",
        "| age_cat   |  Tranche d'âge. Il peut s'agir de < 25, 25-45, >45    |\n",
        "| sex   |  Sexe de l'accusé. Il s'agit soit de « Male » (homme), soit de « Female » (femme)       |\n",
        "| race   |  Race de l'accusé. Il peut s'agir de « African-American » (Afro-Américain), « Caucasian » (Blanc), « Hispanic » (Hispanique), « Asian » (Asiatique) ou « Other » (Autre)      |\n",
        "| c_charge_degree   |   Inculpation. Soit « M » pour délit, « F » pour crime, soit « O » (n'entraînant pas de peine d'emprisonnement)    |\n",
        "| priors_count   |   Nombre de crimes antérieurs commis par l'accusé      |\n",
        "| days_b_screening_arrest   |  Jours entre l'arrestation et l'évaluation COMPAS       |\n",
        "| decile_score   |  Le score COMPAS estimé par le système. Il se situe entre 0 et 10       |\n",
        "| score_text   |  Score décile. Il peut être « Low » (faible) (1-4), « Medium » (moyen) (5-7) ou « High » (élevé) (8-10)       |\n",
        "| is_recid   |  Indique si l'accusé a récidivé. Il peut être égal à 0, 1 ou -1      |\n",
        "| two_year_recid   |  Indique si l'accusé a récidivé dans les deux ans suivant l'évaluation COMPAS      |\n",
        "| c_jail_in   |   Date à laquelle l'accusé était en prison      |\n",
        "| c_jail_out  |   Date à laquelle l'accusé a été libéré de prison     |\n",
        "\n",
        "\\\n",
        "# **TODO 1** Tracer la distribution de l'âge, de la race et du sexe dans les données importées (```df_compas```) :\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha4MebGr5Jd5"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C6lQj5HJVuyw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title Réponse\n",
        "df_compas[\"age\"].hist()\n",
        "plt.xlabel(\"Âge\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "df_compas[\"race\"].value_counts().plot(kind = \"bar\")\n",
        "plt.xlabel(\"Race\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "df_compas[\"sex\"].value_counts().plot(kind = \"bar\")\n",
        "plt.xlabel(\"Sexe\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q36OxXLfoJxt"
      },
      "source": [
        "# Préparer les données\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYL5nnxko0bG"
      },
      "source": [
        "ProPublica a mis en œuvre quelques étapes de prétraitement. Tout d'abord, ils ont généré un sous-ensemble des données avec quelques variables d'intérêt. Ici, nous sélectionnons encore moins de variables, en ne conservant que celles que nous utiliserons dans ce bloc-notes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1qppbDjoRGJ"
      },
      "outputs": [],
      "source": [
        "cols_to_keep = [\"id\", \"age\", \"c_charge_degree\", \"race\", \"age_cat\", \"score_text\",\n",
        "                \"sex\", \"priors_count\", \"days_b_screening_arrest\",\n",
        "                \"decile_score\", \"is_recid\", \"two_year_recid\"]\n",
        "\n",
        "# (df_selected)\n",
        "df_selected = df_compas[cols_to_keep].copy()\n",
        "\n",
        "print(\"Forme : \", df_selected.shape) # Forme\n",
        "df_selected.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghZE7FZUpBsQ"
      },
      "source": [
        "Prenez un moment pour vous familiariser avec les variables et la structure des données. ProPublica a filtré les données ci-dessus en supprimant les lignes où :\n",
        "\n",
        "1.  Le score COMPAS est manquant.\n",
        "2.  La date de l'infraction pour laquelle le score COMPAS du défendeur a été calculé n'était pas dans les 30 jours suivant la date de l'arrestation. ProPublica a supposé que l'infraction pourrait ne pas être correcte dans ces cas.\n",
        "3.  L'indicateur de récidive est « -1 ». Dans de tels cas, ProPublica n'a trouvé aucun enregistrement COMPAS.\n",
        "4.  L'accusation est « O ». Il s'agit d'infractions au code de la route ordinaires qui n'entraînent pas de peine d'emprisonnement.\n",
        "\n",
        "Nous implémentons ces conditions ici :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3muereQrap8u"
      },
      "outputs": [],
      "source": [
        "df_analysis = df_selected[\n",
        "    (df_selected.score_text != \"N/A\") &\n",
        "    (df_selected.days_b_screening_arrest <= 30) &\n",
        "    (df_selected.days_b_screening_arrest >= -30) &\n",
        "    (df_selected.is_recid != -1) &\n",
        "    (df_selected.c_charge_degree != \"O\")\n",
        "    ].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCNlGWB_sBda"
      },
      "source": [
        "Notez que ProPublica n'a inclus que les personnes ayant récidivé dans un délai de deux ans ou ayant passé au moins deux ans hors d'un établissement correctionnel. Cette étape de prétraitement est \"intégrée\" aux données que nous avons importées depuis GitHub dans ce bloc-notes.\n",
        "\n",
        "# **TODO 2** Vérifiez les dimensions (c'est-à-dire le nombre de variables et d'observations) des données importées (```df_compas```) et prétraitées (```df_analysis```) :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPYaEmwW5lse"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JJ_MkWKxt1YJ"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "print(\"Données importées\", df_compas.shape)\n",
        "print(\"Données après la sélection des variables\", df_selected.shape)\n",
        "print(\"Données après le filtrage des observations\", df_analysis.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0juptQDv7pDG"
      },
      "source": [
        "Prenez l'étape supplémentaire de vous assurer que le score de décile (abordé ci-dessous) est numérique :\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjg2B1s47tJr"
      },
      "outputs": [],
      "source": [
        "df_analysis[\"decile_score\"] = pd.to_numeric(df_analysis[\"decile_score\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS1ZlkXTwTrU"
      },
      "source": [
        "# Inspecter les données à nouveau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bgG7Odrk1Wf"
      },
      "source": [
        "# **TODO 3** Inspectez à nouveau les variables importantes dans les données après les étapes de prétraitement. Tracez la distribution de l'âge, de l'origine ethnique et du sexe dans les données prétraitées (```df_analysis```) et comparez ces distributions aux données importées (```df_compas```) :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT0Knt1a5u0Z"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rf4Jdy6QwRAS"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "plt.hist(df_compas[\"age\"], alpha = 0.5, label = \"importé\")\n",
        "plt.hist(df_analysis[\"age\"], alpha = 0.5, label= \"filtré\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.xlabel(\"Âge\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "df_compas[\"race\"].value_counts().plot(kind = \"bar\", alpha=0.5)\n",
        "df_analysis[\"race\"].value_counts().plot(kind = \"bar\", alpha=0.5, color='orange')\n",
        "plt.xlabel(\"Origine ethnique (race)\") # race\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "df_compas[\"sex\"].value_counts().plot(kind = \"bar\", alpha=0.5)\n",
        "df_analysis[\"sex\"].value_counts().plot(kind = \"bar\", color='orange', alpha=0.5)\n",
        "plt.xlabel(\"Sexe (sex)\") # sex\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnlEcgYrwIkw"
      },
      "source": [
        "# **TODO 4** Observez que nous itérons à travers l'analyse de données : importation, inspection et profilage, prétraitement, et profilage à nouveau. Générez un tableau croisé résumant le nombre d'observations par origine ethnique (race) et sexe (sex):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwhuArp05yNX"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sQnZbZDF162n"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "df_analysis.pivot_table(values = [\"id\"], columns = [\"race\"],\n",
        "                        index = \"sex\", aggfunc = lambda x: len(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxkyKFMP3Oxa"
      },
      "source": [
        "# Analyse exploratoire\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9a0-JeX3Wmd"
      },
      "source": [
        "Concentrons-nous sur la variable principale qui nous intéresse : le score de récidive COMPAS. Dans cette analyse exploratoire, nous nous intéressons à la variable nommée « decile_score ».\n",
        "\n",
        "L’analyse de ProPublica note : « Les juges sont souvent confrontés à deux ensembles de scores du système COMPAS : l’un qui classe les personnes en risque élevé, moyen ou faible, et un score décile correspondant. »\n",
        "\n",
        "Tracer la distribution du score décile pour les hommes et pour les femmes. Dans quelle mesure ces distributions diffèrent-elles ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5ntoFh0w-1F3"
      },
      "outputs": [],
      "source": [
        "# tracer le score décile par sexe\n",
        "df_female = df_analysis[(df_analysis.sex == \"Female\")].copy()\n",
        "df_male   = df_analysis[(df_analysis.sex == \"Male\")].copy()\n",
        "\n",
        "fig = plt.figure(figsize = (12, 6))\n",
        "fig.add_subplot(121)\n",
        "\n",
        "plt.hist(df_female[\"decile_score\"], ec = \"white\",\n",
        "         weights = np.ones(len(df_female[\"decile_score\"])) /\n",
        "         len(df_female[\"decile_score\"]))\n",
        "plt.xlabel(\"Score décile (0-10)\")\n",
        "plt.ylabel(\"Pourcentage de cas\")\n",
        "plt.title(\"Scores déciles des femmes défenderesses\") # défendeur, accusé (Defendants)\n",
        "plt.ylim([0, 0.25])\n",
        "\n",
        "fig.add_subplot(122)\n",
        "plt.hist(df_male[\"decile_score\"], ec = \"white\",\n",
        "         weights = np.ones(len(df_male[\"decile_score\"])) /\n",
        "         len(df_male[\"decile_score\"]))\n",
        "plt.xlabel(\"Score décile (0-10)\")\n",
        "plt.ylabel(\"Pourcentage de cas\")\n",
        "plt.title(\"Scores déciles des hommes défendeurs\") # défendeur, accusé (Defendants)\n",
        "plt.ylim([0, 0.25])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDtwnIWk4O_P"
      },
      "source": [
        "# **TODO 5** Qu'en est-il de l'origine ethnique ? Reproduisez les graphiques ci-dessus pour les défendeurs noirs et les défendeurs blancs : # (Black defendants, White defendants)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_Ea1Wdu55jb"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2QRK2jsM3Vvn"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "\n",
        "# Tracer le décile de score par race\n",
        "df_black = df_analysis[(df_analysis.race == \"African-American\")]\n",
        "df_white = df_analysis[(df_analysis.race == \"Caucasian\")]\n",
        "\n",
        "fig = plt.figure(figsize = (12, 6))\n",
        "fig.add_subplot(121)\n",
        "\n",
        "plt.hist(df_black[\"decile_score\"], ec = \"white\",\n",
        "         weights = np.ones(len(df_black[\"decile_score\"])) /\n",
        "         len(df_black[\"decile_score\"]))\n",
        "plt.xlabel(\"Score Décile (0-10)\")\n",
        "plt.ylabel(\"Pourcentage de Cas\")\n",
        "plt.title(\"Scores Décile des Prévenus Noirs\")\n",
        "plt.ylim([0, 0.30])\n",
        "\n",
        "fig.add_subplot(122)\n",
        "plt.hist(df_white[\"decile_score\"], ec = \"white\",\n",
        "         weights = np.ones(len(df_white[\"decile_score\"])) /\n",
        "         len(df_white[\"decile_score\"]))\n",
        "plt.xlabel(\"Score Décile (0-10)\")\n",
        "plt.ylabel(\"Pourcentage de Cas\")\n",
        "plt.title(\"Scores Décile des Prévenus Blancs\")\n",
        "plt.ylim([0, 0.30])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v4KvrqCNaqi"
      },
      "source": [
        "# **TÂCHE 6** Résumez la différence entre la distribution des scores de décile pour les accusés noirs et les accusés blancs (trois phrases maximum) :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsAvmZ457KP"
      },
      "source": [
        "Votre travail ici :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1o9A7VlDWuo"
      },
      "source": [
        "# **TODO 7** Tracer la distribution des « étiquettes de risque » (la variable est nommée \"score_text\") assignées par COMPAS pour les défendeurs noirs et les défendeurs blancs :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-hUKvFj59eN"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "P3tnCwrbDvIe"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "\n",
        "# calcul du groupe à risque par race\n",
        "fig = plt.figure(figsize = (12, 6))\n",
        "\n",
        "fig.add_subplot(121)\n",
        "(df_black[\"score_text\"].value_counts().reindex(['Low', 'Medium', 'High']) /\n",
        "    len(df_black)).plot(kind = \"bar\")\n",
        "plt.xlabel(\"Score Label\")\n",
        "plt.ylabel(\"Pourcentage de cas\")\n",
        "plt.title(\"Répartition des scores pour les accusés noirs\")\n",
        "plt.ylim([0, .7])\n",
        "\n",
        "fig.add_subplot(122)\n",
        "(df_white[\"score_text\"].value_counts().reindex(['Low', 'Medium', 'High']) /\n",
        "    len(df_white)).plot(kind = \"bar\")\n",
        "plt.xlabel(\"Score Label\")\n",
        "plt.ylabel(\"Pourcentage de cas\")\n",
        "plt.title(\"Répartition des scores pour les accusés blancs\")\n",
        "plt.ylim([0, .7])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfFXAqvNFFXi"
      },
      "source": [
        "# Biais dans COMPAS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcvC8rNFbYc"
      },
      "source": [
        "ProPublica s'est concentré sur le biais racial dans l'algorithme COMPAS. En termes généraux, ProPublica a analysé (i) comment les *scores de risque* varient selon l'origine ethnique et (ii) dans quelle mesure les *étiquettes de risque* attribuées aux accusés correspondent à leur récidive observée et comment cela varie selon l'origine ethnique. Nous allons (approximativement) reproduire cette analyse ci-dessous.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOCIMREOQ7I0"
      },
      "source": [
        "## Préparer les données pour la régression logistique\n",
        "\n",
        "ProPublica a utilisé un modèle de régression logistique pour analyser la variation des scores de risque en fonction de l'origine ethnique. Nous allons préparer les données en encodant les variables catégorielles en utilisant le one-hot encoding.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VqJLl5RfFIXR"
      },
      "outputs": [],
      "source": [
        "print(df_analysis.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1VywniiqFugA"
      },
      "outputs": [],
      "source": [
        "for i, col_type in enumerate(df_analysis.dtypes):\n",
        "        if col_type == \"object\":\n",
        "            print(\"\\nLa variable {} prend les valeurs : {}\".format( # Variable (col_type), valeurs (values)\n",
        "                df_analysis.columns[i],\n",
        "                df_analysis[df_analysis.columns[i]].unique()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbPi5iRYHZ64"
      },
      "outputs": [],
      "source": [
        "df_logistic = df_analysis.copy()\n",
        "\n",
        "# encodage one-hot\n",
        "df_logistic = pd.get_dummies(df_logistic,\n",
        "                             columns = [\"c_charge_degree\", \"race\",\n",
        "                                        \"age_cat\", \"sex\"])\n",
        "\n",
        "# transformer score_text en variable binaire où low = {low}\n",
        "# et high = {medium, high}\n",
        "df_logistic[\"score_binary\"] = np.where(df_logistic[\"score_text\"] != \"Low\",\n",
        "                                       \"High\", \"Low\")\n",
        "df_logistic[\"score_binary\"] = df_logistic[\"score_binary\"].astype('category')\n",
        "\n",
        "# renommer les colonnes pour qu'elles soient plus instructives et cohérentes avec les statsmodel\n",
        "# exigences relatives aux noms de variables\n",
        "df_logistic.columns = df_logistic.columns.str.replace(' ', '_')\n",
        "df_logistic.columns = df_logistic.columns.str.replace('-', '_')\n",
        "\n",
        "#  (renamed_cols)\n",
        "renamed_cols = {'age_cat_25___45':'age_cat_25_to_45',\n",
        "                'c_charge_degree_F':'Felony', # Felony (F)\n",
        "                'c_charge_degree_M':'Misdemeanor'} # Misdemeanor (M)\n",
        "\n",
        "df_logistic = df_logistic.rename(columns = renamed_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BaOl-bMfU3q"
      },
      "source": [
        "Vérifiez que le recodage a donné la structure de données souhaitée :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7rAihNgrP3f7"
      },
      "outputs": [],
      "source": [
        "df_logistic.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NKIjUEgRHX6"
      },
      "source": [
        "## Estimer un modèle de régression logistique\n",
        "\n",
        "Suivant ProPublica, nous spécifions le modèle de régression logistique suivant :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Fd07D4i_MUjN"
      },
      "outputs": [],
      "source": [
        "# Variables explicatives\n",
        "    # explicatif (explanatory)\n",
        "explanatory = \"priors_count + two_year_recid + Misdemeanor + \\\n",
        "age_cat_Greater_than_45 + age_cat_Less_than_25 + \\\n",
        "race_African_American + race_Asian + race_Hispanic + race_Native_American + \\\n",
        "race_Other + sex_Female\"\n",
        "\n",
        "# Variable réponse\n",
        "# (response)\n",
        "response = \"score_binary\"\n",
        "\n",
        "# Formule\n",
        "# (formula)\n",
        "formula = response + \" ~ \" + explanatory\n",
        "print(formula)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Gk-XzAfz0d"
      },
      "source": [
        "Ajustons le modèle :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SXGOejPiNk3E"
      },
      "outputs": [],
      "source": [
        "# Remarque : utiliser family = sm.families.Binomial() spécifie une régression logistique\n",
        "model = sm.formula.glm(formula = formula,\n",
        "                       family = sm.families.Binomial(),\n",
        "                       data = df_logistic).fit() # (df_logistic = données pour la régression logistique)\n",
        "\n",
        "print(model.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ7CaxsERKus"
      },
      "source": [
        "## Interpréter les estimations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOE5Yi5dR6rG"
      },
      "source": [
        "Prenez le temps de lire attentivement le résumé du modèle.\n",
        "\n",
        "Une façon d'interpréter les estimations consiste à calculer les rapports de cotes. Pour calculer les rapports de cotes, nous prenons l'exponentielle des coefficients. Par exemple, prendre l'exponentielle du coefficient pour sex_Female ($\\beta_{female}$ = 0.2213) retournera la cote de score_text prenant la valeur \"high\" pour une femme par rapport à un homme.\n",
        "\n",
        "# **TODO 8** Calculer ce rapport de cotes ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILqN3aes6HoS"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m-kJeX2TSu29"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "np.exp(0.2213)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt01yUzKTzG_"
      },
      "source": [
        "En d'autres termes, la probabilité que COMPAS qualifie un accusé de « risque élevé » de récidive est 1,25 fois plus élevée pour une femme que pour un homme.\n",
        "\n",
        "# **TODO 9** Calculer le rapport de cotes pour tous les coefficients du modèle :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKjqygPZ6It2"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8nPb8HKJROFd"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "np.exp(model.params)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRy_qGPaYj-r"
      },
      "source": [
        "Prenez le temps de lire ces coefficients. Quelle est la catégorie de référence pour chaque variable ? (par exemple, pour les femmes, la catégorie de référence est homme). Pensez en termes de comparaisons, par exemple :\n",
        "\n",
        "> Une personne avec une valeur de [ &nbsp; &nbsp; ] sur la variable [ &nbsp; &nbsp; ] a [ &nbsp; &nbsp; ] fois plus de chances d'être étiquetée à haut risque par rapport à une personne avec une valeur de [ &nbsp; &nbsp; ] sur la variable [ &nbsp; &nbsp; ]\n",
        "\n",
        "Dans l'exemple féminin ci-dessus, cela pourrait être dit :\n",
        "\n",
        "> « Une personne avec une valeur de femme sur la variable sexe a 1,25 fois plus de chances d'être étiquetée à haut risque par rapport à une personne avec une valeur d'homme sur la variable sexe »\n",
        "\n",
        "Bien sûr, nous devrions être plus directs lors de la rédaction des résultats. « Une personne avec une valeur d'homme sur la variable sexe » est plutôt verbeux; « hommes » suffira. Interpréter les estimations du modèle en termes simples est une compétence sous-estimée.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dQBzQ5jSjPy"
      },
      "source": [
        "# **TODO 10** Résumez les probabilités associées à la variable \"age_cat\" (deux phrases maximum) :\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VS_hKG-6J1W"
      },
      "source": [
        "Votre travail ici :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvGGSeCqY-eN"
      },
      "source": [
        "## Précision prédictive\n",
        "\n",
        "En termes d'équité, ProPublica s'est concentré sur la précision prédictive de l'algorithme COMPAS. Dans ce cas, la précision prédictive fait référence à la concordance entre la récidive d'une personne et l'étiquette attribuée à cette personne par l'algorithme COMPAS. Par exemple, à quelle fréquence COMPAS a-t-il prédit qu'une personne présentait un « risque élevé » de récidive et que cette personne a effectivement récidivé dans un délai de deux ans ? Nous pouvons penser à cela en termes de tableau 2x2 :\n",
        "\n",
        "|      | N'a pas récidivé | A récidivé   |\n",
        "| :---        |    :----:   |          ---: |\n",
        "| **Étiqueté à risque élevé**  | A       | B   |\n",
        "| **Étiqueté à faible risque**   | C       | D      |\n",
        "\n",
        "ProPublica a rapporté A et D pour les accusés noirs et les accusés blancs, séparément.\n",
        "\n",
        "# **TODO 11** Quels sont les termes génériques pour A et D ? Pourquoi se concentrer sur A et D ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yYTiIE96ffY"
      },
      "source": [
        "Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zVwL9M6yzk"
      },
      "source": [
        "ProPublica a utilisé un ensemble de données quelque peu différent pour calculer la précision prédictive de COMPAS. Dans cette section, nous utiliserons les données ```df_logistic``` que nous avons prétraitées ci-dessus par souci de concision. Notez donc que les chiffres que nous calculons ci-dessous ne correspondent pas à ceux rapportés par ProPublica. Générons un tableau croisé de la variable dénotant la récidive dans les deux ans (```is_recid```) et de la variable de score binaire (```score_binary```) :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JpluSwppZFUe"
      },
      "outputs": [],
      "source": [
        "print(\"Tous les défendeurs\")\n",
        "pd.crosstab(df_logistic[\"score_binary\"], df_logistic[\"is_recid\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kojOZPLybCSv"
      },
      "source": [
        "# **À FAIRE 12** En vous basant sur ce tableau croisé, indiquez le nombre de vrais positifs, de faux positifs, de vrais négatifs et de faux négatifs :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Av4Eu0ZjFN"
      },
      "outputs": [],
      "source": [
        "true_positive = 1817#@param {type:\"number\"}\n",
        "false_positive = 934#@param {type:\"number\"}\n",
        "true_negative = 2248#@param {type:\"number\"}\n",
        "false_negative = 1173#@param {type:\"number\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOKUOXBh6rh0"
      },
      "source": [
        "Vous pouvez calculer le taux de faux positifs en prenant FP / (FP + TN), où FP est le nombre de faux positifs et TN est le nombre de vrais négatifs. Calculez le taux de faux positifs :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uZS5nvV6k_3"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VrkCFBzAZa2R"
      },
      "outputs": [],
      "source": [
        "#@title Answer / titre Réponse\n",
        "print(\"All defendants\")\n",
        "print(\"False positive rate\",\n",
        "false_positive / (false_positive + true_negative) * 100) # (taux de faux positifs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgmNak0ob2C8"
      },
      "source": [
        "# **TODO 13** Maintenant, calculez le taux de *faux négatifs* : (indice : remplacez les termes dans la formule du taux de faux positifs dans la cellule de texte précédente)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-MvPI4A6mgA"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46bwGfLba3ij"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "print(\"Tous les défendeurs\")\n",
        "print(\"Taux de faux négatifs\",\n",
        "      false_negative / (false_negative + true_positive) * 100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1LBhe-f-TTn"
      },
      "source": [
        "# **TODO 14** Comment les taux de faux positifs et de faux négatifs varient-ils selon le sexe ? Générons un tableau croisé de \"score_binary\" et \"is_recid\" pour les femmes accusées et calculons les taux de faux positifs et de faux négatifs pour les femmes :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HmdqzAC6obN"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LI3i9zzt-kMG"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "mask = df_logistic[\"sex_Female\"] == 1\n",
        "print(pd.crosstab(df_logistic.loc[mask, \"score_binary\"],\n",
        "                  df_logistic.loc[mask, \"is_recid\"]))\n",
        "print(\"Female defendants\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8tzBrFZKb4UI"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "tp = 256\n",
        "fp = 220\n",
        "tn = 520\n",
        "fn = 179\n",
        "print(\"False positive rate\", fp / (fp + tn) * 100) # (fp: faux positifs, tn: vrais négatifs)\n",
        "print(\"False negative rate\", fn / (fn + tp) * 100) # (fn: faux négatifs, tp: vrais positifs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYowpvPWcooI"
      },
      "source": [
        "# **TODO 15** Calculer maintenant les taux de faux positifs et de faux négatifs pour les accusés de sexe masculin :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF3fHREC6tHM"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dlxlpA9SARFT"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "mask = df_logistic[\"sex_Male\"] == 1\n",
        "print(pd.crosstab(df_logistic.loc[mask, \"score_binary\"],\n",
        "                  df_logistic.loc[mask, \"is_recid\"]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yexu8ZUIb78V"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "print(\"Prévenus de sexe masculin\") # Male defendants\n",
        "tp = 1561\n",
        "fp = 714\n",
        "tn = 1728\n",
        "fn = 994\n",
        "print(\"Taux de faux positifs\", fp / (fp + tn) * 100) # Taux de faux positifs (False positive rate)\n",
        "print(\"Taux de faux négatifs\", fn / (fn + tp) * 100) # Taux de faux négatifs (False negative rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y3odoqE-g0y"
      },
      "source": [
        "# **TODO 16** Comment les taux de faux positifs et de faux négatifs varient-ils selon l'origine ethnique ? Calculez le taux de faux positifs et le taux de faux négatifs pour les accusés blancs :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT1YJCJJ6uVj"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_0-offlbBQTy"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "mask = df_logistic[\"race_Caucasian\"] == 1\n",
        "print(pd.crosstab(df_logistic.loc[mask, \"score_binary\"],\n",
        "                  df_logistic.loc[mask, \"is_recid\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OZ3qx2aGcGxm"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "print(\"Accusés blancs\")\n",
        "tp = 430\n",
        "fp = 266\n",
        "tn = 963\n",
        "fn = 444\n",
        "print(\"Taux de faux positifs\", fp / (fp + tn) * 100)\n",
        "print(\"Taux de faux négatifs\", fn / (fn + tp) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU0ft0TSe_1m"
      },
      "source": [
        "# **TODO 17** Finalement, calculez le taux de faux positifs et le taux de faux négatifs pour les accusés noirs :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwMqwCli6vOR"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HUU_w57EfEDk"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "mask = df_logistic[\"race_African_American\"] == 1\n",
        "print(pd.crosstab(df_logistic.loc[mask, \"score_binary\"],\n",
        "                  df_logistic.loc[mask, \"is_recid\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kasSRZjkcYET"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "print(\"Accusés noirs\")\n",
        "tp = 1248\n",
        "fp = 581\n",
        "tn = 821\n",
        "fn = 525\n",
        "print(\"Taux de faux positifs\", fp / (fp + tn) * 100) # (fp: faux positifs, tn: vrais négatifs)\n",
        "print(\"Taux de faux négatifs\", fn / (fn + tp) * 100) # (fn: faux négatifs, tp: vrais positifs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "253jTpcO60Mf"
      },
      "source": [
        "# **Deuxième partie : Détection et atténuation des biais à l'aide de Fairlearn**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LrSVlCSDA9Z"
      },
      "source": [
        "#Détection du biais à l'aide de Fairlearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuBQtfv5iZac"
      },
      "source": [
        "## Biais en ML\n",
        "\n",
        "Un algorithme de machine learning tentera de trouver des modèles, ou des généralisations, dans l'ensemble de données d'entraînement à utiliser lorsqu'une prédiction pour une nouvelle instance est nécessaire. Par exemple, le modèle peut découvrir un modèle selon lequel une personne ayant un salaire supérieur à 40 000 $ et une dette en cours inférieure à 5 $ est très susceptible de rembourser un prêt.\n",
        "\n",
        "Cependant, il arrive que les modèles trouvés et reproduits par un modèle ne soient pas souhaitables ou, pire encore, illégaux. Par exemple, un modèle de remboursement de prêt peut déterminer que l'âge joue un rôle important dans la prédiction du remboursement parce que l'ensemble de données d'entraînement s'est avéré avoir un meilleur remboursement pour une tranche d'âge par rapport à une autre. Cela soulève deux problèmes : 1) l'ensemble de données d'entraînement peut ne pas être représentatif de la population réelle des demandes de prêt pour toutes les tranches d'âge, et 2) même s'il est représentatif, il est illégal (à quelques exceptions près) de fonder les décisions de prêt sur l'âge d'un demandeur, que cela constitue ou non une base de prédiction précise d'après les données historiques.\n",
        "\n",
        "Le scénario du prêt décrit un exemple intuitif de biais illégal. Cependant, tous les biais indésirables en matière de machine learning ne sont pas illégaux ; ils peuvent également exister de manière plus subtile. Par exemple, une société de prêt peut souhaiter un portefeuille diversifié de clients à tous les niveaux de revenu, et jugera donc indésirable de consentir davantage de prêts aux personnes à revenu élevé qu'aux personnes à faible revenu. Bien que cela ne soit ni illégal ni contraire à l'éthique, c'est indésirable pour la stratégie de l'entreprise.\n",
        "\n",
        "## La boîte à outils `Fairlearn`\n",
        "\n",
        "Fairlearn est une boîte à outils conçue pour aider à résoudre ce problème grâce à des métriques d'équité et des atténuateurs de biais. Les métriques d'équité peuvent être utilisées pour vérifier la présence de biais dans les workflows de machine learning. Les atténuateurs de biais peuvent être utilisés pour surmonter les biais dans le workflow afin de produire un résultat plus équitable.\n",
        "\n",
        "Comme ces deux exemples l'illustrent, une boîte à outils de détection et/ou d'atténuation des biais doit être adaptée au biais particulier qui nous intéresse. Plus précisément, nous devons définir le ou les attributs, appelés attributs protégés (ou sensibles) d'intérêt : l'attribut dont nous essayons de détecter et d'atténuer l'asymétrie/le biais. Ce terme suggère que le concepteur du système doit être sensible à ces caractéristiques lorsqu'il évalue et atténue l'équité de groupe.\n",
        "\n",
        "Plusieurs étapes du pipeline de machine learning sont susceptibles d'être biaisées. Une façon utile de classer ces étapes consiste, intuitivement, à les distinguer « avant », « pendant » et « après » l'entraînement d'un modèle. Ces étapes sont communément appelées *prétraitement*, *traitement en cours* et *post-traitement* (dans Fairlearn, les techniques de traitement en cours sont disponibles dans le package *reductions*).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip6sQt0eQLAU"
      },
      "source": [
        "## Fairlearn\n",
        "\n",
        "Dans la partie 2, nous allons utiliser Fairlearn pour détecter et atténuer les biais dans un classificateur. Nous utiliserons les [fichiers ACS PUMS](https://www.census.gov/programs-surveys/acs/microdata.html), en particulier une fraction de l'ensemble de données ACS Income, et nous allons entraîner un classificateur pour prédire si un individu a un salaire supérieur à 50 000 $. L'attribut protégé sera le sexe de l'individu.\n",
        "\n",
        "Dans la partie 2, nous allons :\n",
        "\n",
        "1. Explorer les métriques d'équité possibles\n",
        "2. Entraîner un classificateur de régression logistique et évaluer l'équité de ce classificateur\n",
        "3. Entraîner d'autres classificateurs de régression logistique avec des interventions de prétraitement et réévaluer l'équité\n",
        "4. Comparer les résultats obtenus en 2 et 3\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XttcS7t0SNbL"
      },
      "source": [
        "#1. Charger les données, effectuer une analyse exploratoire et prétraiter les données\n",
        "Ensuite, nous allons charger le jeu de données Folktables. Le jeu de données Folktables est tiré des données du recensement américain et est conçu pour résoudre quelques tâches de prédiction simples. L'échantillon que nous extrayons est constitué de données de 2018 en Californie. Les noms des colonnes sont décrits dans le tableau ci-dessous. Notez que certaines variables catégorielles ont été mappées à des valeurs entières, que nous conserverons telles quelles pour les analyses suivantes.\n",
        "\n",
        "Pour plus d'informations sur ce jeu de données, veuillez consulter l'article suivant (notamment la page 18) : https://eaamo2021.eaamo.org/accepted/acceptednonarchival/EAMO21_paper_16.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJSui-veHGd"
      },
      "source": [
        "| Nom de la colonne | Caractéristique | Description/Remarques |\n",
        "| --- | ----------- | --- |\n",
        "| PINCP | Revenu total de la personne | (Cible) 1 si >= 50 000 $, 0 si inférieur |\n",
        "| SEX | Sexe | (Attribut sensible) Homme=1, Femme=2 |\n",
        "| RAC1P | Race | (Attribut sensible) Blanc=1, Noir=2, Autres races entre 3 et 9 |\n",
        "| AGEP | Âge | Varie de 0 à 99 |\n",
        "| COW | Classe de travailleur | Varie de 1 à 9, voir l'article pour la description |\n",
        "| SCHL | Niveau d'éducation | Varie de 1 à 24, voir l'article pour la description |\n",
        "| MAR | État matrimonial | Varie de 1 à 5, voir l'article pour la description |\n",
        "| OCCP | Profession | Codes tirés de l'échantillon de microdonnées à usage public (PUMS) du recensement américain, voir l'article |\n",
        "| POBP | Lieu de naissance | Codes tirés de l'échantillon de microdonnées à usage public (PUMS) du recensement américain, voir l'article |\n",
        "| RELP | Lien de parenté | Lien de parenté de l'individu avec la personne qui a répondu au recenseur. Varie de 0 à 17, voir l'article pour la description |\n",
        "| WKHP | Heures travaillées par semaine | Varie de 0 à 99, en moyenne sur l'année précédente |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MgVUEi3nET1p"
      },
      "outputs": [],
      "source": [
        "# Lire le jeu de données folktables\n",
        "    # Lisons le jeu de données folktables\n",
        "full_df, features_df, target_df, groups_df = ACSData().return_acs_data_scenario(scenario=\"ACSIncome\", subsample=70000)\n",
        "\n",
        "print(full_df.shape)\n",
        "full_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9D-hmorRFKia"
      },
      "outputs": [],
      "source": [
        "# Vérifier les valeurs manquantes et les types de données\n",
        "full_df.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1x2mdUaID9G"
      },
      "outputs": [],
      "source": [
        "# modifier les types de données des caractéristiques catégorielles\n",
        "numerical_cols = ['AGEP','WKHP']\n",
        "categorical_cols = ['COW','SCHL','MAR','OCCP','POBP','RELP','RAC1P','SEX']\n",
        "\n",
        "for col in categorical_cols:\n",
        "  full_df[col] = full_df[col].astype('int')\n",
        "  full_df[col] = full_df[col].astype('str')\n",
        "\n",
        "full_df.info()\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHRpGsboZ_wa"
      },
      "source": [
        "Ensuite, nous allons effectuer une analyse exploratoire basique des données en commençant par tracer les distributions de nos caractéristiques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "umsO2aZ3J3WT"
      },
      "outputs": [],
      "source": [
        "# Tracer la distribution des colonnes catégorielles\n",
        "fig, ax = plt.subplots(2,4,figsize=(12,8))\n",
        "ax[0,0].barh(full_df['COW'].value_counts().index[::-1], full_df['COW'].value_counts()[::-1])\n",
        "ax[0,0].set_title('COW')\n",
        "\n",
        "ax[0,1].barh(full_df['SCHL'].value_counts().index[:10][::-1], full_df['SCHL'].value_counts()[:10][::-1])\n",
        "ax[0,1].set_title('SCHL (top-10)')\n",
        "\n",
        "ax[0,2].barh(full_df['MAR'].value_counts().index[::-1], full_df['MAR'].value_counts()[::-1])\n",
        "ax[0,2].set_title('MAR')\n",
        "\n",
        "ax[0,3].barh(full_df['OCCP'].value_counts().index[:10][::-1], full_df['OCCP'].value_counts()[:10][::-1])\n",
        "ax[0,3].set_title('OCCP (top-10)')\n",
        "\n",
        "ax[1,0].barh(full_df['POBP'].value_counts().index[:10][::-1], full_df['POBP'].value_counts()[:10][::-1])\n",
        "ax[1,0].set_title('POBP (top-10)')\n",
        "\n",
        "ax[1,1].barh(full_df['RELP'].value_counts().index[:10][::-1], full_df['RELP'].value_counts()[:10][::-1])\n",
        "ax[1,1].set_title('RELP (top-10)')\n",
        "\n",
        "ax[1,2].barh(full_df['SEX'].value_counts().index[::-1], full_df['SEX'].value_counts()[::-1])\n",
        "ax[1,2].set_title('SEX')\n",
        "labels = ('Female = 2', 'Male = 1')\n",
        "ax[1,2].set_yticklabels(labels)\n",
        "\n",
        "ax[1,3].barh(full_df['RAC1P'].value_counts().index[::-1], full_df['RAC1P'].value_counts()[::-1])\n",
        "ax[1,3].set_title('RAC1P')\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fIN5VbbVQT4_"
      },
      "outputs": [],
      "source": [
        "# Tracé de la distribution des caractéristiques numériques\n",
        "fig, ax = plt.subplots(1,2,figsize=(12,8))\n",
        "\n",
        "#histogramme pour AGEP (âge)\n",
        "num_of_bins_agep = 10\n",
        "y_vals_agep, x_vals_agep, e_agep = ax[0].hist(full_df['AGEP'], bins=num_of_bins_agep, edgecolor='black')\n",
        "ax[0].set_title(\"Histogramme de AGEP\")\n",
        "ax[0].set_xlabel(\"âge\") # (age)\n",
        "ax[0].set_ylabel(\"Pourcentage\")\n",
        "y_max_agep = round((max(y_vals_agep) / len(full_df)) + 0.02, 2)\n",
        "ax[0].set_yticks(ticks=np.arange(0.0, y_max_agep * len(full_df), 0.01 * len(full_df)))\n",
        "ax[0].set_ylim(ax[0].get_yticks()[0], ax[0].get_yticks()[-1])\n",
        "ax[0].yaxis.set_major_formatter(ticker.PercentFormatter(xmax=len(full_df)))\n",
        "\n",
        "#histogramme pour WKHP (Heures travaillées par semaine)\n",
        "num_of_bins_wkhp = 10\n",
        "y_vals_wkhp, x_vals_wkhp, e_wkhp = ax[1].hist(full_df['WKHP'], bins=num_of_bins_wkhp, edgecolor='black')\n",
        "ax[1].set_title(\"Histogramme de WKHP\")\n",
        "ax[1].set_xlabel(\"heures travaillées par semaine\") # heures travaillées par semaine\n",
        "ax[1].set_ylabel(\"Pourcentage\")\n",
        "y_max_wkhp = round((max(y_vals_wkhp) / len(full_df)) + 0.05, 2)\n",
        "ax[1].set_yticks(ticks=np.arange(0.0, y_max_wkhp * len(full_df), 0.05 * len(full_df)))\n",
        "ax[1].set_ylim(ax[1].get_yticks()[0], ax[1].get_yticks()[-1])\n",
        "ax[1].yaxis.set_major_formatter(ticker.PercentFormatter(xmax=len(full_df)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhrMJoM1sOrj"
      },
      "source": [
        "Comme nous pouvons le constater, la distribution des caractéristiques de ce jeu de données n'a rien de très inhabituel. On note également que la proportion d'hommes et de femmes est plutôt équilibrée.\n",
        "\n",
        "On peut également examiner les corrélations par paires entre les caractéristiques numériques et notre variable cible.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KXO7X2tMyTI6"
      },
      "outputs": [],
      "source": [
        "# Tracé des corrélations par paires entre les caractéristiques numériques\n",
        "\n",
        "sns.heatmap(full_df.corr(), mask=np.identity(len(full_df.corr())), annot=True, cmap='Blues')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kyJCKQ3yxhQ"
      },
      "source": [
        "Ici, nous pouvons voir qu'il n'y a que des corrélations relativement faibles entre notre variable cible (PINCP) et nos caractéristiques numériques d'âge et d'heures travaillées par semaine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL6p5-Axxbvh"
      },
      "source": [
        "Ensuite, nous pouvons examiner la distribution de notre variable cible ainsi que la distribution conjointe de nos attributs protégés et cibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7JCRb5o76oiH"
      },
      "outputs": [],
      "source": [
        "# Examiner la distribution de la variable cible (target variable)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "full_df['PINCP'].value_counts().divide(full_df.shape[0]).plot(kind='bar')\n",
        "ax.set_xlabel('Revenu (Income)')\n",
        "ax.set_ylabel('Fréquence (Frequency)')\n",
        "plt.setp(ax.get_xticklabels(), rotation=0, ha='center')\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
        "labels_target = ('0 (<$50k)', '1 (>=$50k)')\n",
        "ax.set_xticklabels(labels_target)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq9_1ZSXduNs"
      },
      "source": [
        "D'après le graphique ci-dessus, nous remarquons un déséquilibre considérable de la variable cible (target variable). Voyons à quoi ressemble cette distribution selon le sexe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rWqWUOfamsAm"
      },
      "outputs": [],
      "source": [
        "#Afficher la distribution de la variable cible (target variable) chez les hommes et la distribution de la variable cible chez les femmes\n",
        "hist_df = full_df.groupby(['SEX','PINCP']).size().to_frame('count').reset_index()\n",
        "new_col = full_df.groupby(['SEX']).PINCP.value_counts(normalize=True).values\n",
        "hist_df['frac'] = new_col\n",
        "hist_df.replace({'SEX': {'1': 'Homme', '2': 'Femme'}}, inplace=True)\n",
        "hist_df.replace({'PINCP': {0.0: '<$50k', 1.0: '>=$50k'}}, inplace=True)\n",
        "sns.barplot(x='PINCP', y='frac', hue='SEX', data=hist_df)\n",
        "plt.ylabel('Pourcentage du groupe')\n",
        "plt.xlabel('Revenu (Income)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mb4qHH0dQYAB"
      },
      "outputs": [],
      "source": [
        "# Affichage du nombre d'hommes et de femmes par groupe de revenu (Income group)\n",
        "full_df.groupby(['SEX', 'PINCP'])['PINCP'].count()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lB_TQJGE1tV"
      },
      "source": [
        "Ici, nous pouvons constater que la proportion d'hommes qui gagnent au moins $50 000 $ est plus élevée que la proportion de femmes qui gagnent au moins $50 000 $ dans cet ensemble de données. Ainsi, la constatation initiale concernant le déséquilibre de la variable cible est plus accentuée pour les femmes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ffXieBGVGx"
      },
      "source": [
        "# **TODO 1**: Étant donné les graphiques ci-dessus, à quels résultats pouvons-nous nous attendre de la part de notre classificateur lorsqu'il s'agira d'étiqueter les hommes et les femmes comme ayant un revenu élevé ou faible ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P62gK8l07Hh_"
      },
      "source": [
        "Votre réponse ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p2T0SGz9hVS"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "'''Étant donné que la proportion d'hommes dans ce jeu de données qui gagnent au moins 50 000 $ est plus élevée que la proportion de femmes dans ce jeu de données\n",
        "qui gagnent au moins 50 000 $, nous pourrions nous attendre à ce que notre classificateur ait un biais pour étiqueter les hommes comme ayant un revenu plus élevé que les femmes.'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1-hPuYr-vV1"
      },
      "source": [
        "<!-- **Réponse :** Étant donné que la proportion d'hommes dans ce jeu de données qui gagnent au moins 50 000 $ est plus élevée que la proportion de femmes dans ce jeu de données\n",
        "qui gagnent au moins 50 000 $, nous pourrions nous attendre à ce que notre classificateur ait un biais pour étiqueter les hommes comme ayant un revenu plus élevé que les femmes. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vccos4UWJieU"
      },
      "source": [
        "# **TODO 2** : Pourquoi ces données pourraient-elles être biaisées ? De quel type de biais s'agit-il ?\n",
        "\n",
        "<!-- **Réponse :** Les hommes pourraient être plus enclins que les femmes à gonfler les déclarations de leurs revenus réels. De plus, il existe des disparités historiques documentées dans la rémunération entre les hommes et les femmes pour un travail similaire pour diverses raisons (disparités dans l'éducation, le marché du travail, etc.). Par conséquent, les différences de revenus dans cet ensemble de données pourraient être le reflet d'un écart salarial réel. Ces deux exemples seraient des exemples de « biais préexistants » dans cet ensemble de données. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntofxi1T7JTX"
      },
      "source": [
        "Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4TMUf_9_4Jx"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "'''Les hommes pourraient être plus enclins que les femmes à gonfler les rapports sur leurs revenus réels. De plus, il existe des écarts de rémunération historiques et documentés entre les hommes et les femmes pour un travail similaire, et ce, pour diverses raisons (écarts de niveau de scolarité, marché du travail, etc.). Par conséquent, les différences de revenus dans cet ensemble de données pourraient refléter un écart de rémunération réel. Ces deux exemples illustrent les « biais préexistants » dans cet ensemble de données.'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khnT4aDn7Pfh"
      },
      "source": [
        "#**TODO 3**: Écrivez un code qui reproduit l'histogramme ci-dessus pour les personnes noires et blanches dans les données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc4N54Sq7eHh"
      },
      "outputs": [],
      "source": [
        "#Votre travail ici :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nQP7PQb0BGWv"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "hist_df = full_df.groupby(['RAC1P','PINCP']).size().to_frame('count').reset_index()\n",
        "new_col = full_df.groupby(['RAC1P']).PINCP.value_counts(normalize=True).values\n",
        "hist_df['frac'] = new_col\n",
        "# (RAC1P: Race)\n",
        "hist_df['RAC1P'] = hist_df['RAC1P'].map({'1': 'Blanc', '2': 'Noir'}).fillna('Autre')\n",
        "# (PINCP: Revenu (Income))\n",
        "hist_df.replace({'PINCP': {0.0: '<$50k', 1.0: '>=$50k'}}, inplace=True)\n",
        "sns.barplot(x='PINCP', y='frac', hue='RAC1P', data=hist_df)\n",
        "plt.ylabel('Pourcentage par groupe')\n",
        "plt.xlabel('Revenu')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7mYHwvvrlZn"
      },
      "source": [
        "## Prétraitement\n",
        "Ensuite, nous allons effectuer un prétraitement sur nos données afin de les préparer à être utilisées dans notre modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UJmRpooUU6cC"
      },
      "outputs": [],
      "source": [
        "# standardiser les variables numériques\n",
        "scaler = StandardScaler()\n",
        "full_df[numerical_cols] = scaler.fit_transform(full_df[numerical_cols])\n",
        "display(full_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ttOb_ULRsGUB"
      },
      "outputs": [],
      "source": [
        "# Encodage one-hot des variables catégorielles\n",
        "full_df = pd.get_dummies(full_df, columns=categorical_cols)\n",
        "display(full_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1rLw5F6_sHew"
      },
      "outputs": [],
      "source": [
        "# Puisque l'attribut sexe est déjà binaire, on peut supprimer une des colonnes redondantes\n",
        "#note: les hommes sont maintenant étiquetés 1 et les femmes sont étiquetés 0\n",
        "full_df.drop(columns=['SEX_2'], inplace=True)\n",
        "full_df.rename(columns={'SEX_1':'SEX'}, inplace=True)\n",
        "\n",
        "full_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lldcQFkCx1Y5"
      },
      "source": [
        "#2. Entraîner un classificateur de régression logistique\n",
        "Ensuite, nous allons diviser nos données en ensembles d'entraînement et de test de manière aléatoire. Puis, nous allons entraîner un classificateur de régression logistique et évaluer les biais possibles au sein de ce classificateur.\n",
        "\n",
        "### Aparté : La précision comme métrique\n",
        "\n",
        "Le ML traditionnel (c'est-à-dire sans accent sur l'équité) mesure souvent la qualité d'un classificateur par sa **précision**, ou la fraction d'échantillons qui ont été étiquetés correctement :\n",
        "$$\n",
        "\\text{Précision} = \\frac{\\text{Nombre de personnes étiquetées correctement}}{\\text{Nombre total de personnes}}\n",
        "$$\n",
        "Ceci peut également être exprimé en utilisant les termes de la [\"matrice de confusion\"](https://fr.wikipedia.org/wiki/Matrice_de_confusion), où nous avons\n",
        "- $\\text{TP} = $ \"Vrais positifs\" $ = \\text{Nombre de personnes correctement étiquetées comme positives}$\n",
        "- $\\text{FP} = $ \"Faux positifs\" $ = \\text{Nombre de personnes incorrectement étiquetées comme positives}$\n",
        "- $\\text{TN} = $ \"Vrais négatifs\" $ = \\text{Nombre de personnes correctement étiquetées comme négatives}$\n",
        "- $\\text{FN} = $ \"Faux négatifs\" $ = \\text{Nombre de personnes incorrectement étiquetées comme négatives}$\n",
        "\n",
        "Ce qui nous permet d'exprimer la précision comme suit :\n",
        "$$\n",
        "\\text{Précision} = \\frac{TP + TN}{TP + FP + TN + FN}\n",
        "$$\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ugcIGIK_XDxC"
      },
      "outputs": [],
      "source": [
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "target = full_df['PINCP']\n",
        "full_df.drop(columns='PINCP', inplace=True)\n",
        "\n",
        "#note: ici, nous définissons une valeur pour le paramètre random_state (graine) afin que les résultats de ce laboratoire restent cohérents\n",
        "X_train, X_test, y_train, y_test = train_test_split(full_df, target, test_size=0.2, random_state=4)\n",
        "\n",
        "# (X_train, X_test : données d'entraînement et de test, y_train, y_test : étiquettes correspondantes)\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4otIko99As5"
      },
      "source": [
        "#**TODO 4**: Quelle serait la précision ($\\frac{(VP + VN)}{(VP + FP + VN + FN)}$) d'un classificateur qui prédit toujours la classe majoritaire (classificateur de base) ?\n",
        "Étant donné que la classe majoritaire est 0, la précision de ce classificateur de classe majoritaire serait le nombre de 0 sur le nombre total d'enregistrements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNi0kX4CBOyM"
      },
      "outputs": [],
      "source": [
        "# Votre réponse ici :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NlbkMZZEoFxG"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "# Donner aux étudiants ce qui suit :\n",
        "# y_test.value_counts()\n",
        "# # print(f'General baseline accuracy: {baseline_accuracy:.4f}')\n",
        "\n",
        "target_zero = y_test.value_counts()[0] # target_zero : nombre d'éléments avec target = 0\n",
        "target_one = y_test.value_counts()[1] # target_one : nombre d'éléments avec target = 1\n",
        "baseline_accuracy = target_zero / (target_zero+target_one)\n",
        "\n",
        "print(f'General baseline accuracy: {baseline_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA9jjuc-BXDm"
      },
      "source": [
        "#**TODO 5**: Quelle serait l'accuracy ($\\frac{(TP + TN)}{(TP + FP + TN + FN)}$) pour les groupes Homme et Femme en considérant un classifieur qui prédit toujours la classe majoritaire (classifieur de base) pour chacun de ces groupes ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOhMjYUWBcOZ"
      },
      "outputs": [],
      "source": [
        "# Your work here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FHt5VXJefZ8L"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "# # print(f'Précision de base chez les hommes (Male baseline accuracy): {male_baseline_accuracy:.4f}')\n",
        "# # print(f'Précision de base chez les femmes (Female baseline accuracy): {female_baseline_accuracy:.4f}')\n",
        "\n",
        "# On récupère le nombre d'hommes avec 'Outcome' (y_test) = 0 (male_zero) et = 1 (male_one)\n",
        "male_zero = y_test[X_test['SEX']==1].value_counts()[0]\n",
        "male_one = y_test[X_test['SEX']==1].value_counts()[1]\n",
        "male_baseline_accuracy = male_zero / (male_zero + male_one)\n",
        "print(f'Male baseline accuracy: {male_baseline_accuracy:.4f}')\n",
        "\n",
        "# On récupère le nombre de femmes avec 'Outcome' (y_test) = 0 (female_zero) et = 1 (female_one)\n",
        "female_zero = y_test[X_test['SEX']==0].value_counts()[0]\n",
        "female_one = y_test[X_test['SEX']==0].value_counts()[1]\n",
        "female_baseline_accuracy = female_zero / (female_zero + female_one)\n",
        "print(f'Female baseline accuracy: {female_baseline_accuracy:.4f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d6f1ZdiyXSE3"
      },
      "outputs": [],
      "source": [
        "# Implémentation de la régression logistique\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "clf_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(f'Logistic Regression test accuracy: {clf_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9vugXFztlG8"
      },
      "source": [
        "## Évaluer l'équité\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlGbK5w4x7q-"
      },
      "source": [
        "## Évaluer l'équité\n",
        "\n",
        "Ensuite, nous allons évaluer l'équité de notre classificateur sur l'ensemble de test. Nous définissons d'abord le **taux de sélection** du classificateur sur un groupe :\n",
        "$$\n",
        "\\text{Taux de sélection} = \\frac{\\text{Nombre de personnes classées positives}}{\\text{Nombre total de personnes}}\n",
        "$$\n",
        "Nous allons calculer le taux de sélection chez les hommes et chez les femmes, et les comparer. La différence entre leurs taux de sélection est appelée **différence de parité démographique**, et le ratio de leurs taux est appelé **ratio de parité démographique**.\n",
        "\n",
        "En général, si nous avons plus de 2 classes,\n",
        "- La différence de parité démographique est la différence entre le taux de sélection le plus élevé et le taux de sélection le plus faible, elle est donc toujours positive. Une différence de parité démographique de 0 signifie que tous les groupes ont le même taux de sélection.\n",
        "\n",
        "- Le ratio de parité démographique est le ratio du plus petit au plus grand taux de sélection, il est donc toujours compris entre 0 et 1, où un ratio de 1 signifie que tous les groupes ont le même taux de sélection.\n",
        "\n",
        "<!-- Next, we will evaluate the fairness of our classifier on the test set.  We will first focus on two metrics - demographic parity difference and demographic parity ratio.  **Demographic parity difference** is defined as the difference between the largest and the smallest group-level selection rate across all values of the sensitive feature(s).  A demographic parity difference of 0 means that all groups have the same selection rate.  **Demographic parity ratio** is defined as the ratio between the smallest and the largest group-level selection rate across all values of the sensitive feature(s).  A demographic parity ratio of 1 means that all groups have the same selection rate. -->\n",
        "\n",
        "Plus formellement : soit $X$ un vecteur de caractéristiques utilisé pour les prédictions, $A$ une seule caractéristique sensible (comme l'âge ou l'origine ethnique), $Y$ le vrai label, et $h$ un classificateur ou prédicteur résultant d'un algorithme de ML. Alors:\n",
        "\n",
        "*Différence de parité démographique* est définie comme $(max_a\\mathbb{E}[h(X)~|~  A = a])~ - ~ (min_a\\mathbb{E}[h(X)~|~  A = a]) $\n",
        "\n",
        "\n",
        "*Ratio de parité démographique* est défini comme $\\frac{max_a\\mathbb{E}[h(X)~|~  A = a]}{min_a\\mathbb{E}[h(X)~|~  A = a]} $\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S9-CPsT9bhhy"
      },
      "outputs": [],
      "source": [
        "# Évaluer l'équité du classificateur à l'aide de `demographic_parity_difference` et `demographic_parity_ratio`\n",
        "#note: nous menons cette analyse sur l'ensemble de test\n",
        "\n",
        "#calculer les prédictions du test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "#calculer la différence de parité démographique et le ratio de parité démographique\n",
        "# (demo_parity_diff, demo_parity_ratio)\n",
        "demo_parity_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=X_test['SEX'])\n",
        "demo_parity_ratio = demographic_parity_ratio(y_test, y_pred, sensitive_features=X_test['SEX'])\n",
        "\n",
        "print(f'Différence de parité démographique: {demo_parity_diff:.4f}')\n",
        "print(f'Ratio de parité démographique: {demo_parity_ratio:.4f}')\n",
        "\n",
        "#calculer le taux de sélection pour les hommes et les femmes\n",
        "#(male_selection_rate, female_selection_rate)\n",
        "male_selection_rate = selection_rate(y_test[X_test['SEX']==1], y_pred[X_test['SEX']==1])\n",
        "female_selection_rate = selection_rate(y_test[X_test['SEX']==0], y_pred[X_test['SEX']==0])\n",
        "\n",
        "print(f'Taux de sélection des hommes: {male_selection_rate:.4f}')\n",
        "print(f'Taux de sélection des femmes: {female_selection_rate:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbwDQ2nQ8c_J"
      },
      "source": [
        "Ici, nous pouvons constater qu'il existe des différences substantielles dans les taux de sélection entre les hommes et les femmes, les hommes étant beaucoup plus susceptibles d'être classés dans la catégorie des revenus élevés.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxWyzIlKyHIH"
      },
      "source": [
        "Fairlearn fournit également la classe **fairlearn.metrics.MetricFrame** pour évaluer les disparités de traitement entre différentes sous-populations.\n",
        "\n",
        "L'objet **fairlearn.metrics.MetricFrame** nécessite au minimum quatre arguments :\n",
        "\n",
        "*   La ou les fonctions de métrique sous-jacentes à évaluer\n",
        "*   Les vraies valeurs (true values)\n",
        "*   Les valeurs prédites (predicted values)\n",
        "*   Les valeurs des caractéristiques sensibles (sensitive feature values)\n",
        "\n",
        "Les fonctions de métrique doivent avoir une signature ''fn(y_true, y_pred)'', c'est-à-dire ne nécessiter que deux arguments. Nous allons à nouveau examiner le taux de sélection, mais nous allons également examiner quelques autres métriques.  Nous utiliserons la précision (accuracy), le taux de sélection (selection rate), le taux de faux négatifs (false negative rate) et le taux de faux positifs (false positive rate).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lhzxtUcmay1"
      },
      "outputs": [],
      "source": [
        "# Évaluer l'équité du classificateur en utilisant la classe MetricFrame pour la variable `SEX`\n",
        "\n",
        "#changer les entrées de caractéristiques sensibles pour qu'elles soient 'male' et 'female' au lieu de 1 et 0\n",
        "#(sensitive_feature_sex) variable sensible sexe\n",
        "sensitive_feature_sex = X_test['SEX'].replace({0:'female', 1:'male'})\n",
        "\n",
        "#métriques d'évaluation\n",
        "#(metrics) métriques\n",
        "metrics = {'accuracy': skm.accuracy_score,\n",
        "           'selection_rate': selection_rate,  # i.e., the percentage of the population which have ‘1’ as their predicted label\n",
        "           'FNR': false_negative_rate,\n",
        "           'FPR': false_positive_rate\n",
        "           }\n",
        "\n",
        "#(grouped_on_sex) groupé par sexe\n",
        "grouped_on_sex = MetricFrame(metrics=metrics,\n",
        "                             y_true=y_test,\n",
        "                             y_pred=y_pred,\n",
        "                             sensitive_features=sensitive_feature_sex)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-AAN3eYyOrh"
      },
      "source": [
        "La classe **fairlearn.metrics.MetricFrame** a la propriété **overall**, qui évalue les métriques sur l'ensemble du jeu de données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPuojgxHm4EG"
      },
      "outputs": [],
      "source": [
        "grouped_on_sex.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4BCINzEB0Sq"
      },
      "source": [
        "# **TODO 6**: Évaluer l'équité pour la variable `RAC1P` (pour les individus noirs et blancs au minimum), et afficher `grouped_on_race.overall`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3EGFfrgB6bu"
      },
      "outputs": [],
      "source": [
        "# Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG4i1QxPYDm9"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "sensitive_feature_race = (X_test['RAC1P_1'] + 2 * X_test['RAC1P_2'] ).replace({0:'autre', 1:'blanc', 2:'noir'})\n",
        "indices = sensitive_feature_race != 'autre'\n",
        "#métriques d'évaluation\n",
        "metrics = {'accuracy': skm.accuracy_score,\n",
        "           'selection_rate': selection_rate,  # c'est-à-dire le pourcentage de la population dont l'étiquette prédite est « 1 »\n",
        "           'FNR': false_negative_rate,\n",
        "           'FPR': false_positive_rate\n",
        "           }\n",
        "\n",
        "# (race)\n",
        "grouped_on_race = MetricFrame(metrics=metrics,\n",
        "                             y_true=y_test[indices],\n",
        "                             y_pred=y_pred[indices],\n",
        "                             sensitive_features=sensitive_feature_race[indices])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mITEvRncj68m"
      },
      "outputs": [],
      "source": [
        "print(y_pred[indices].shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD4OsxeWbXjW"
      },
      "outputs": [],
      "source": [
        "grouped_on_race.overall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr-EFAs8yQBd"
      },
      "source": [
        "L'objet **fairlearn.metrics.MetricFrame** possède également la fonctionnalité **by_group**. Celle-ci affiche les métriques sélectionnées évaluées sur chaque sous-groupe défini par les catégories dans les sensitive_features (le sexe dans notre cas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4KM3xmxm9Ng"
      },
      "outputs": [],
      "source": [
        "grouped_on_sex.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nft2D0xUCDwK"
      },
      "source": [
        "# **TODO 7**: Afficher également pour `RAC1P`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGMGBT9cCIaq"
      },
      "outputs": [],
      "source": [
        "# Votre travail ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaYBo98cbbJK"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "grouped_on_race.by_group\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNr0r1yIIE3Y"
      },
      "source": [
        "Reminder: Females are labeled 0 and males are labeled 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5B9z7HUdm_up"
      },
      "outputs": [],
      "source": [
        "# Traçons les valeurs des métriques (metrics)\n",
        "\n",
        "metrics_1 = {'accuracy': skm.accuracy_score,\n",
        "           'selection_rate': selection_rate,  # c'est-à-dire le pourcentage de la population dont l'étiquette prédite est \"1\".\n",
        "           }\n",
        "\n",
        "metrics_2 = {\n",
        "           'FNR': false_negative_rate,\n",
        "           'FPR': false_positive_rate\n",
        "           }\n",
        "\n",
        "grouped_on_sex_accuracy_selection = MetricFrame(metrics=metrics_1,\n",
        "                             y_true=y_test,\n",
        "                             y_pred=y_pred,\n",
        "                             sensitive_features=sensitive_feature_sex)\n",
        "\n",
        "grouped_on_sex_fpr_fnr = MetricFrame(metrics=metrics_2,\n",
        "                             y_true=y_test,\n",
        "                             y_pred=y_pred,\n",
        "                             sensitive_features=sensitive_feature_sex)\n",
        "\n",
        "grouped_on_sex_accuracy_selection.by_group.plot.bar(\n",
        "    subplots=False,\n",
        "    figsize=(10, 7),\n",
        "    ylim=[0,1],\n",
        "    title=\"Précision (accuracy) et taux de sélection (selection rate) par sexe\",\n",
        "    )\n",
        "\n",
        "grouped_on_sex_fpr_fnr.by_group.plot.bar(\n",
        "    subplots=False,\n",
        "    figsize=(10, 7),\n",
        "    ylim=[0,1],\n",
        "    title=\"Taux de faux négatifs (FNR) et taux de faux positifs (FPR) par sexe\",\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le-jOMssCNF3"
      },
      "source": [
        "#**À FAIRE 8** : Reproduisez les graphiques ci-dessus pour `RAC1P` et au moins pour les personnes noires/blanches dans les données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYkR6AGkCSCb"
      },
      "outputs": [],
      "source": [
        "# Votre réponse ici :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PK3tfGI-bjAy"
      },
      "outputs": [],
      "source": [
        "# @title Réponse\n",
        "grouped_on_race_accuracy_selection = MetricFrame(metrics=metrics_1,\n",
        "                             y_true=y_test,\n",
        "                             y_pred=y_pred,\n",
        "                             sensitive_features=sensitive_feature_race)\n",
        "\n",
        "grouped_on_race_fpr_fnr = MetricFrame(metrics=metrics_2,\n",
        "                             y_true=y_test,\n",
        "                             y_pred=y_pred,\n",
        "                             sensitive_features=sensitive_feature_race)\n",
        "\n",
        "grouped_on_race_accuracy_selection.by_group.plot.bar(\n",
        "    subplots=False,\n",
        "    figsize=(10, 7),\n",
        "    ylim=[0,1],\n",
        "    title=\"Précision et taux de sélection par origine ethnique\", # précision, taux de sélection (accuracy, selection rate)\n",
        "    )\n",
        "\n",
        "grouped_on_race_fpr_fnr.by_group.plot.bar(\n",
        "    subplots=False,\n",
        "    figsize=(10, 7),\n",
        "    ylim=[0,1],\n",
        "    title=\"Taux de faux négatifs (FNR) et taux de faux positifs (FPR) par origine ethnique\", # FNR, FPR\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH7SZrv2N8ot"
      },
      "source": [
        "# **À FAIRE 9**: Observez que la précision pour les groupes hommes et femmes est comparable, mais que nous constatons des disparités dans les taux de FPR et de FNR.  Quel groupe bénéficie des écarts dans les FPR et FNR indiqués ci-dessus ? Si vous déployiez ce système, comment mesureriez-vous les performances (par exemple, la précision, le FNR, le FPR) ? (Rappel : les femmes sont étiquetées 0, les hommes sont étiquetés 1)\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrK8z_xKCaX_"
      },
      "source": [
        "Votre réponse ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5Zq_gseCce2"
      },
      "outputs": [],
      "source": [
        "#@title Réponse\n",
        "'''\n",
        "<Les hommes bénéficient à la fois d'un taux de faux négatifs plus faible et d'un taux de faux positifs plus élevé. Ils sont moins susceptibles d'être classés à tort\n",
        "comme ayant un « faible revenu » et sont également plus susceptibles d'être classés à tort comme ayant un « revenu élevé ». Lors de la conception d'un classificateur, nous voudrions regarder\n",
        "au-delà de la précision et du taux de sélection et tenir compte des FPR et FNR.'''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFqCzXyXyhcO"
      },
      "source": [
        "#3. Entraîner un classificateur de régression logistique « aveugle » (équité par l'ignorance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cJPVQ7byn53"
      },
      "source": [
        "Ensuite, nous allons supprimer l'attribut protégé \"sex\" de nos données et voir quel effet cela a sur les performances de notre classificateur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGZewKk9tBbZ"
      },
      "outputs": [],
      "source": [
        "#Supprimer l'attribut sensible des données\n",
        "X_train_blind = X_train.drop(columns='SEX')\n",
        "X_test_blind = X_test.drop(columns='SEX')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "P-0MCOFjtL9l"
      },
      "outputs": [],
      "source": [
        "# Implémenter la régression logistique\n",
        "clf_blind = LogisticRegression()\n",
        "clf_blind.fit(X_train_blind, y_train)\n",
        "clf_blind_accuracy = clf_blind.score(X_test_blind, y_test)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(f'Exactitude du test de régression logistique (sans attribut sensible) : {clf_blind_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5Svx5AUycMC5"
      },
      "outputs": [],
      "source": [
        "# Rappelons l'équité de l'exactitude du classificateur d'origine\n",
        "print('Rappelons le classificateur d\\'origine :')\n",
        "print(f'Exactitude du test de régression logistique : {clf_accuracy:.4f}')\n",
        "print(f'Différence de parité démographique : {demo_parity_diff:.4f}')\n",
        "print(f'Ratio de parité démographique : {demo_parity_ratio:.4f}')\n",
        "print(f'Taux de sélection des hommes : {male_selection_rate:.4f}')\n",
        "print(f'Taux de sélection des femmes : {female_selection_rate:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bEg0YU9Ltbzh"
      },
      "outputs": [],
      "source": [
        "# Évaluer l'équité du classificateur aveugle\n",
        "\n",
        "#calculer les prédictions du test\n",
        "y_pred_blind = clf_blind.predict(X_test_blind)\n",
        "\n",
        "#calculer la différence de parité démographique et le ratio de parité démographique\n",
        "# (demo_parity_diff_blind, demo_parity_ratio_blind)\n",
        "demo_parity_diff_blind = demographic_parity_difference(y_test, y_pred_blind, sensitive_features=X_test['SEX'])\n",
        "demo_parity_ratio_blind = demographic_parity_ratio(y_test, y_pred_blind, sensitive_features=X_test['SEX'])\n",
        "\n",
        "print(f'Différence de parité démographique (sans attribut sensible) : {demo_parity_diff_blind:.4f}')\n",
        "print(f'Ratio de parité démographique (sans attribut sensible) : {demo_parity_ratio_blind:.4f}')\n",
        "\n",
        "#calculer le taux de sélection pour les hommes et les femmes\n",
        "# (male_selection_rate_blind, female_selection_rate_blind)\n",
        "male_selection_rate_blind = selection_rate(y_test[X_test['SEX']==1], y_pred_blind[X_test['SEX']==1])\n",
        "female_selection_rate_blind = selection_rate(y_test[X_test['SEX']==0], y_pred_blind[X_test['SEX']==0])\n",
        "\n",
        "print(f'Taux de sélection des hommes (sans attribut sensible) : {male_selection_rate_blind:.4f}')\n",
        "print(f'Taux de sélection des femmes (sans attribut sensible) : {female_selection_rate_blind:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yueobvhd78gp"
      },
      "source": [
        "# **TODO 10:** Décrivez les différences entre les deux modèles en termes de précision et d'équité entre les groupes hommes et femmes ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7nVQqVuC3r5"
      },
      "source": [
        "Votre réponse ici :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qzR6FjRVC48Q"
      },
      "outputs": [],
      "source": [
        "'''Ici, nous pouvons constater que la suppression de l'attribut protégé de nos données a eu un impact minime sur la précision du modèle. En revanche,\n",
        "les indicateurs d'équité se sont considérablement améliorés à mesure que la différence de parité démographique a diminué et que le ratio de parité démographique a augmenté.'''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVVozeK0IYV"
      },
      "source": [
        "**Néanmoins**, nous constatons que la suppression de la caractéristique protégée n'a pas éliminé les biais au sein de notre classificateur, comme illustré ci-dessous.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FP75qKmuC6_"
      },
      "outputs": [],
      "source": [
        "# Évaluer les biais du classificateur à l'aide de la classe MetricFrame\n",
        "#(blind = sans caractéristique protégée)\n",
        "grouped_on_sex_blind = MetricFrame(metrics=metrics,\n",
        "                                     y_true=y_test,\n",
        "                                     y_pred=y_pred_blind,\n",
        "                                     sensitive_features=sensitive_feature_sex)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0l6FUGluMWh"
      },
      "outputs": [],
      "source": [
        "grouped_on_sex_blind.overall\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DwAXmgKcuR0M"
      },
      "outputs": [],
      "source": [
        "grouped_on_sex_blind.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zENn3IQzsNjR"
      },
      "source": [
        "## Affichage de toutes les métriques pour les données complètes et les données aveugles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TOyiVARo16T"
      },
      "outputs": [],
      "source": [
        "#Comparaison des résultats : données complètes vs. données aveugles\n",
        "\n",
        "#différence de parité démographique\n",
        "# (demo_parity_diff, demo_parity_diff_blind)\n",
        "demo_parity_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=X_test['SEX'])\n",
        "demo_parity_diff_blind = demographic_parity_difference(y_test, y_pred_blind, sensitive_features=X_test['SEX'])\n",
        "\n",
        "#ratio de parité démographique\n",
        "# (demo_parity_ratio, demo_parity_ratio_blind)\n",
        "demo_parity_ratio = demographic_parity_ratio(y_test, y_pred, sensitive_features=X_test['SEX'])\n",
        "demo_parity_ratio_blind = demographic_parity_ratio(y_test, y_pred_blind, sensitive_features=X_test['SEX'])\n",
        "\n",
        "#taux de sélection\n",
        "# (male_selection_rate, male_selection_rate_blind)\n",
        "male_selection_rate = selection_rate(y_test[X_test['SEX']==1], y_pred[X_test['SEX']==1])\n",
        "male_selection_rate_blind = selection_rate(y_test[X_test['SEX']==1], y_pred_blind[X_test['SEX']==1])\n",
        "\n",
        "# (female_selection_rate, female_selection_rate_blind)\n",
        "female_selection_rate = selection_rate(y_test[X_test['SEX']==0], y_pred[X_test['SEX']==0])\n",
        "female_selection_rate_blind = selection_rate(y_test[X_test['SEX']==0], y_pred_blind[X_test['SEX']==0])\n",
        "\n",
        "#fnr (taux de faux négatifs)\n",
        "# (male_fnr, male_fnr_blind)\n",
        "male_fnr = false_negative_rate(y_test[X_test['SEX']==1], y_pred[X_test['SEX']==1])\n",
        "male_fnr_blind = false_negative_rate(y_test[X_test['SEX']==1], y_pred_blind[X_test['SEX']==1])\n",
        "\n",
        "# (female_fnr, female_fnr_blind)\n",
        "female_fnr = false_negative_rate(y_test[X_test['SEX']==0], y_pred[X_test['SEX']==0])\n",
        "female_fnr_blind = false_negative_rate(y_test[X_test['SEX']==0], y_pred_blind[X_test['SEX']==0])\n",
        "\n",
        "#fpr (taux de faux positifs)\n",
        "# (male_fpr, male_fpr_blind)\n",
        "male_fpr = false_positive_rate(y_test[X_test['SEX']==1], y_pred[X_test['SEX']==1])\n",
        "male_fpr_blind = false_positive_rate(y_test[X_test['SEX']==1], y_pred_blind[X_test['SEX']==1])\n",
        "\n",
        "# (female_fpr, female_fpr_blind)\n",
        "female_fpr = false_positive_rate(y_test[X_test['SEX']==0], y_pred[X_test['SEX']==0])\n",
        "female_fpr_blind = false_positive_rate(y_test[X_test['SEX']==0], y_pred_blind[X_test['SEX']==0])\n",
        "\n",
        "#graphique\n",
        "labels = ['Diff. Parité Démo.','Ratio Parité Démo.','Taux Sélection (Homme)',\n",
        "          'Taux Sélection (Femme)', 'FNR (Homme)', 'FNR (Femme)', 'FPR (Homme)',\n",
        "          'FPR (Femme)']\n",
        "\n",
        "Y_full = [demo_parity_diff, demo_parity_ratio, male_selection_rate,\n",
        "          female_selection_rate, male_fnr, female_fnr, male_fpr, female_fpr]\n",
        "\n",
        "Y_blind = [demo_parity_diff_blind, demo_parity_ratio_blind,\n",
        "           male_selection_rate_blind, female_selection_rate_blind, male_fnr_blind,\n",
        "           female_fnr_blind, male_fpr_blind, female_fpr_blind]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "rects1 = ax.bar(x - width/2, Y_full, width, label='Modèle Complet')\n",
        "rects2 = ax.bar(x + width/2, Y_blind, width, label='Modèle Aveugle')\n",
        "\n",
        "ax.set_title('Comparaison des Métriques', size=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend(fontsize='x-large')\n",
        "ax.bar_label(rects1, padding=3, fmt='%.3f')\n",
        "ax.bar_label(rects2, padding=3, fmt='%.3f')\n",
        "ax.set_ylim([0, 1])\n",
        "fig.tight_layout()\n",
        "plt.rcParams[\"figure.figsize\"] = (18,8)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3YG7QOZD-B"
      },
      "source": [
        "## Conclusion\n",
        "**Résumé :**\n",
        "\n",
        "Biais dans les systèmes d'IA : Le laboratoire a commencé par examiner les biais raciaux et sexistes de l'outil COMPAS dans les prédictions de récidive, illustrant la nécessité de l'équité dans l'IA.\n",
        "\n",
        "Reproduction de l'analyse : Les participants ont reproduit les conclusions de ProPublica en utilisant l'ensemble de données COMPAS, en se concentrant sur la régression logistique pour détecter les schémas de biais.\n",
        "\n",
        "Équité avec Fairlearn : Le laboratoire a présenté Fairlearn pour évaluer et atténuer les biais dans les modèles de Machine Learning, en utilisant l'ensemble de données ACS pour aborder l'équité dans les prédictions liées au sexe.\n",
        "\n",
        "Atténuer les biais : Des étapes pratiques pour améliorer l'équité des modèles ont été abordées, notamment la modélisation sensible à l'équité et les ajustements pour équilibrer performance et équité.\n",
        "\n",
        "IA responsable : Le laboratoire souligne l'importance de lutter contre les biais dans les systèmes d'IA et fournit des outils et des idées pour mettre en œuvre des pratiques d'IA responsables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ndpYE50BpG"
      },
      "source": [
        "## Feedback\n",
        "\n",
        "Merci de nous fournir vos commentaires afin que nous puissions améliorer nos travaux pratiques à l'avenir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIZvkhfRz9Jz"
      },
      "outputs": [],
      "source": [
        "# @title Générer un formulaire de commentaires (Exécuter la cellule)\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    \"\"\"\n",
        "<iframe\n",
        "\tsrc=\"https://forms.gle/WUpRupqfhFtbLXtN6\",\n",
        "  width=\"80%\"\n",
        "\theight=\"1200px\" >\n",
        "\tLoading...\n",
        "</iframe>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oglV4kHMWnIN"
      },
      "source": [
        "<img src=\"https://baobab.deeplearningindaba.com/static/media/indaba-logo-dark.d5a6196d.png\" width=\"50%\" />\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JI0slRqXFyXZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}